{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bJTr-Sv18Jsp"
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade llama-index-llms-together llama-index llama-index-embeddings-jinaai llama-index-vector-stores-chroma docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1d1pFueL4dJ"
   },
   "source": [
    "### What is Retrieval Augmented Generation (RAG)?\n",
    "RAG is a technique that enhances language models by combining them with a retrieval system. It allows the model to access and utilize external knowledge when generating responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTwMayJCNLAn"
   },
   "source": [
    "The process typically involves:\n",
    "#### Indexing a large corpus of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynuxRM7_-Nhu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"\"\n",
    "os.environ[\"JINAAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkGT7MDh-mGk"
   },
   "source": [
    "### Call LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFPaXjak-Dx6",
    "outputId": "92d3ee0c-0b89-42b1-c785-ae205be75d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "What do you call a fake noodle?\n",
      "\n",
      "An impasta.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.together import TogetherLLM\n",
    "\n",
    "llm = TogetherLLM(\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    ")\n",
    "\n",
    "\n",
    "llm_response = llm.complete(\"Tell me a joke\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59Hl3OjvsA02"
   },
   "source": [
    "### LLM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37riQcz1FoB_",
    "outputId": "587f2a11-252a-42c4-cda9-72d34d9fc7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Me hearty! Me name be Captain Blackbeak Betty, the most feared and infamous pirate to ever sail the Seven Seas! Me be a swashbucklin' scallywag with a heart o' gold and a spirit o' adventure. Me ship, the \"Maverick's Revenge\", be me home, and me trusty cutlass, \"Betsy\", be me best mate.\n",
      "\n",
      "Now, what be bringin' ye to these fair waters? Are ye lookin' to join me crew and sail the seas in search o' treasure and glory? Or be ye just lookin' to test yer mettle against the greatest pirate to ever hoist the Jolly Roger? Either way, I be warnin' ye: I be a pirate o' me word, and I don't take kindly to landlubbers or scurvy dogs! Arrr!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-G_ZBmiSJRP",
    "outputId": "dff7dcf0-6445-4a78-9184-73007a91a7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "\n",
    "documents = SimpleDirectoryReader(\"/content/drive/MyDrive/Colab Notebooks/rag_lamaindex/docs/\").load_data()\n",
    "\n",
    "print(len(documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8kOuWreVFL_"
   },
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jC5JDmOmVFL_"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PromptHelper\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=300, chunk_overlap=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zluMkIRZVFL_"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "41HPbx5tVFMA"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.jinaai import JinaEmbedding\n",
    "\n",
    "embed_model = JinaEmbedding(\n",
    "    api_key=os.environ[\"JINAAI_API_KEY\"],\n",
    "    model=\"jina-embeddings-v3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN2g-2-GVFMA"
   },
   "source": [
    "## Set Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1cX56WbYVFMA"
   },
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.num_output = 512\n",
    "Settings.context_window = 4096\n",
    "Settings.chunk_overlap_ratio = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgBuC-Xdu5gL"
   },
   "source": [
    "### Create and persist Chroma vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5Ov-ElhBUpJB"
   },
   "outputs": [],
   "source": [
    "db = chromadb.PersistentClient(path=\"/content/drive/MyDrive/Colab Notebooks/rag_lamaindex/chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"my_collection\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    settings = Settings\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmphRCgFc5dT"
   },
   "source": [
    "## Query Engine Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMzOPWrQVFMB",
    "outputId": "26f02956-011a-4bd6-ce1d-14d281fea1f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 میں\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"نیکسٹ ویو ٹیکنالوجیز کی بنیاد کب رکھی گئی؟\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvYdb5XefxDi"
   },
   "source": [
    "## Chat Engine Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FhdLIAffctJ",
    "outputId": "7af09735-1f46-44d7-b32b-ef9bdeea35ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نیکسٹ ویو ٹیکنالوجیز 2010 میں قائم ہوئی تھی۔\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_chat_engine()\n",
    "response = query_engine.chat(\"نیکسٹ ویو ٹیکنالوجیز کی بنیاد کب رکھی گئی؟\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_ZaR-sNf9Ub"
   },
   "source": [
    "## Query Engine English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IehEl9KBf9Uc",
    "outputId": "11760522-3304-4409-e175-8c3ef6f63e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"When was TechNova Solutions founded?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1VsBJILf9Uc"
   },
   "source": [
    "## Chat Engine English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OGFFL3zf9Uc",
    "outputId": "e8418baa-b5ca-485c-b70e-98bc125b9613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TechNova Solutions was founded in 2015.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_chat_engine()\n",
    "response = query_engine.chat(\"When was TechNova Solutions founded?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APwqrEKffjob",
    "outputId": "fe80e557-cd81-4cfb-808f-3d4d14ece768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website of TechNova Solutions is www.technovasolutions.com.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_chat_engine()\n",
    "response = query_engine.chat(\"What is the website of TechNova Solutions?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
